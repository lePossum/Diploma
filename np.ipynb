{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# from tensorflow.compat.v1 import keras\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread, imsave, imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.signal import convolve2d\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "from skimage.transform import resize\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras import Sequential\n",
    "# from keras import layers\n",
    "import copy\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import gc\n",
    "import os.path\n",
    "gc.enable()\n",
    "\n",
    "# tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "# sess = tf.Session() \n",
    "# keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "def make_ker(ker_len, ker_angle):\n",
    "#     h = ker_len * 2\n",
    "    h = ker_len\n",
    "    ker_len = ker_len // 2\n",
    "    ker = np.zeros((h, h), dtype='float')\n",
    "    k = -math.tan(ker_angle)\n",
    "    b = (1 - k) * ker_len\n",
    "    if abs(abs(ker_angle * 180/math.pi) - 90) > 10:\n",
    "        for x in range(h):\n",
    "            y = round(k * x + b)\n",
    "            y = int((y if y >= 0 else 0) if y <= h-1 else h-1)\n",
    "            if (y == 0 or y == h - 1):\n",
    "                continue\n",
    "            ker[y, x] = 1\n",
    "    else:\n",
    "        for y in range(h):\n",
    "            ker[y, ker_len] = 1 \n",
    "    ret_value = ker/ker.sum()\n",
    "    if np.isnan(np.sum(ret_value)):\n",
    "        return []\n",
    "    else:\n",
    "        return ret_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# def get_available_gpus():\n",
    "#     local_device_protos = device_lib.list_local_devices()\n",
    "#     return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "# get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.transform import SimilarityTransform\n",
    "from skimage.transform import warp\n",
    "from skimage.util import random_noise\n",
    "\n",
    "IMG_SIZE = 200\n",
    "BLUR_LEN = 5\n",
    "# IMG_SIZE = None\n",
    "# OUT_SIZE = 600\n",
    "BATCH_SIZE = 8\n",
    "EPS = 10e-7\n",
    "\n",
    "def rotate_transform_matrix(transform):\n",
    "    \"\"\"Rotate matrix so it can be applied to row:col coordinates.\"\"\"\n",
    "    matrix = transform.params[(1, 0, 2), :][:, (1, 0, 2)]\n",
    "    return type(transform)(matrix)\n",
    "\n",
    "def prepare_img(img):\n",
    "    image = copy.copy(img)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image, image, image))\n",
    "        image = np.transpose(image, axes=(1,2, 0))\n",
    "    for channel in range(3):\n",
    "        image[:,:,channel] = (image[:,:,channel] - np.mean(image[:,:,channel])) / (np.std(image[:,:,channel]) + EPS)\n",
    "    if (image.shape[2] == 4):\n",
    "        image = image[:,:,:3]\n",
    "    h, w = image.shape[:2]\n",
    "    return image\n",
    "\n",
    "def prepare_img1(img):\n",
    "    image = copy.copy(img)\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack((image, image, image))\n",
    "        image = np.transpose(image, axes=(1,2, 0))\n",
    "    if (image.shape[2] == 4):\n",
    "        image = image[:,:,:3]\n",
    "    return img_as_float(image)\n",
    "\n",
    "# train_generator = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1)\n",
    "# train_generator.fit(X, augment=True, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ea7ea5447bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     def __init__(self,  blur_paths, sharp_paths=None, batch_size=BATCH_SIZE,\n\u001b[0;32m      3\u001b[0m                  shuffle=True, seed=None):\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblur_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblur_paths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,  blur_paths, sharp_paths=None, batch_size=BATCH_SIZE,\n",
    "                 shuffle=True, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.blur_paths = blur_paths\n",
    "        self.sharp_paths = sharp_paths\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        if seed:\n",
    "            random.seed(seed)\n",
    "        else:\n",
    "            random.seed(42)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.blur_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        image_batch = [self.blur_paths[k] for k in indexes]\n",
    "        y_batch = [self.sharp_paths[k] for k in indexes]\n",
    "        X, y = self.__data_generation(image_batch, y_batch)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.blur_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, image_batch, y_batch):\n",
    "        X = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3))\n",
    "        y = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # image = prepare_img1(imread(image_batch[i]))\n",
    "            # X[i,] = image\n",
    "            # y[i,] = resize(imread(y_batch[i])[y_idx : y_idx + crop, x_idx : x_idx + crop, :], (OUT_SIZE, OUT_SIZE))\n",
    "            X[i,] = prepare_img1(imread(image_batch[i]))[ :IMG_SIZE, :IMG_SIZE]\n",
    "            y[i,] = prepare_img1(imread(y_batch[i]))[ :IMG_SIZE, :IMG_SIZE]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 600\n",
    "BLUR_LEN = 10\n",
    "KER = make_ker(BLUR_LEN, 0)\n",
    "global_idx = 0\n",
    "\n",
    "def generate_pics(paths, amount_on_picture, break_on = 0):\n",
    "    global global_idx\n",
    "    for p in paths:\n",
    "        try:\n",
    "            cur_img = prepare_img1(imread(p))\n",
    "            blurred = convolve_img(cur_img)\n",
    "            noised = random_noise(blurred, var=0.001)\n",
    "            h, w = cur_img.shape[:2]\n",
    "            if (h > IMG_SIZE and w > IMG_SIZE):\n",
    "                for idx in range(amount_on_picture):\n",
    "                    y = random.randrange(h - IMG_SIZE)\n",
    "                    x = random.randrange(w - IMG_SIZE)\n",
    "                    plt.imsave('pict/random_la/bn/img_' + str(global_idx) + '.png', noised[y : y + IMG_SIZE, x : x + IMG_SIZE])\n",
    "                    plt.imsave('pict/random_la/sn/img_' + str(global_idx) + '.png', cur_img[y : y + IMG_SIZE, x : x + IMG_SIZE])\n",
    "                    global_idx += 1\n",
    "            if (break_on != 0):\n",
    "                if (break_on == global_idx):\n",
    "                    return\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def generate_pics_from_two(paths_X, paths_y, amount_on_picture):\n",
    "    global_idx = 0\n",
    "    for p in range(len(paths_X)):\n",
    "        blurred = prepare_img1(imread(paths_X[p]))\n",
    "        cur_img = prepare_img1(imread(paths_y[p]))\n",
    "        h, w = cur_img.shape[:2]\n",
    "        for idx in range(amount_on_picture):\n",
    "            y = random.randrange(h - IMG_SIZE)\n",
    "            x = random.randrange(w - IMG_SIZE)\n",
    "            plt.imsave('pict/b_test/test_' + str(global_idx) + '.png', blurred[y : y + IMG_SIZE, x : x + IMG_SIZE])\n",
    "            plt.imsave('pict/s_test/test_' + str(global_idx) + '.png', cur_img[y : y + IMG_SIZE, x : x + IMG_SIZE])\n",
    "            global_idx += 1\n",
    "    return\n",
    "\n",
    "def convolve_img(image):\n",
    "    # ker = KER\n",
    "        ker = make_ker(random.randint(2, 15), random.uniform(0, np.pi))\n",
    "        ker_len = BLUR_LEN\n",
    "        pad = ker_len // 2\n",
    "        img = image\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.stack((image, image, image))\n",
    "            img = np.transpose(image, axes=(1,2, 0))\n",
    "        # for channel in range(3):\n",
    "            # image[:,:,channel] = (image[:,:,channel] - np.mean(image[:,:,channel])) / (np.std(image[:,:,channel]) + EPS)\n",
    "        r = convolve2d(np.pad(img[:,:,0], pad, 'edge'), ker, mode='valid'); #r /= r.max()\n",
    "        g = convolve2d(np.pad(img[:,:,1], pad, 'edge'), ker, mode='valid'); #g /= g.max()\n",
    "        b = convolve2d(np.pad(img[:,:,2], pad, 'edge'), ker, mode='valid'); #b /= b.max()\n",
    "        image = np.stack((r, g, b))\n",
    "        image = np.clip(image, 0., 1.)\n",
    "        image = np.transpose(image, axes=(1,2, 0))\n",
    "        return image\n",
    "        print(ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# generate_pics_from_two(X, y, 1)\n",
    "generate_pics(y, 1, break_on=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 79 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dir = '../course/motion_blurred/'\n",
    "# train_dir = 'b/'\n",
    "y_dir = 'pict/google_initial/'\n",
    "# y_dir = 'pict/s_/'\n",
    "# y_dir = 's/'\n",
    "fnames_X = listdir(train_dir)\n",
    "fnames_y = listdir(y_dir)\n",
    "\n",
    "X = list([train_dir + item for item in fnames_X])\n",
    "y = list([y_dir + item for item in fnames_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "\n",
    "def calc_metrics(predicted_dir, target_dir):\n",
    "    pred_files = listdir(predicted_dir)\n",
    "    targ_files = listdir(target_dir)\n",
    "    \n",
    "    metrics = dict()\n",
    "    metrics['PSNR'] = 0\n",
    "    metrics['SSIM'] = 0\n",
    "    for idx in range(len(pred_files)):\n",
    "        t = prepare_img1(imread(os.path.join(target_dir, targ_files[idx])))\n",
    "        p = prepare_img1(imread(os.path.join(predicted_dir, pred_files[idx])))\n",
    "        metrics['PSNR'] += PSNR(t,p)\n",
    "        metrics['SSIM'] += SSIM(t,p, multichannel=True)\n",
    "\n",
    "    metrics['PSNR'] /= len(pred_files)\n",
    "    metrics['SSIM'] /= len(pred_files)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = calc_metrics('pict/bn_val', 'pict/sn_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = calc_metrics('pict/sn_val', 'result/bn_val_orig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = calc_metrics('pict/sn_val', 'result/bn_val_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = calc_metrics('pict/sn_val', 'result/bn_val_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = calc_metrics('pict/sn_val', 'pict/predicted_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = calc_metrics('pict/sn_val', 'pict/predicted_val1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Метрики на датасете:\nСравнение размытых изображений с изначальными:\n  {'PSNR': 23.425286662747613, 'SSIM': 0.6817486902035588}\nВосстановленные Inception без дообучения:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e194a93fdc95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'  '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Восстановленные Inception без дообучения:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'  '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Восстановленное Inception после дообучения (6 эпох):'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'  '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "print('Метрики на датасете:')\n",
    "print('Сравнение размытых изображений с изначальными:')\n",
    "print('  ' + str(m0))\n",
    "print('Восстановленные Inception без дообучения:')\n",
    "print('  ' + str(m1))\n",
    "print('Восстановленное Inception после дообучения (6 эпох):')\n",
    "print('  ' + str(m2))\n",
    "print('Восстановленное Inception после дообучения (20 эпох):')\n",
    "print('  ' + str(m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}